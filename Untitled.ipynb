{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dda524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.0.184)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.26.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.11.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kishore\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d63582",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9ce52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to load YOLOv4 model\n",
    "def load_yolo_model(model_path, config_path, classes_path):\n",
    "    net = cv2.dnn.readNet(model_path, config_path)\n",
    "    with open(classes_path, \"r\") as f:\n",
    "        classes = f.read().strip().split(\"\\n\")\n",
    "    return net, classes\n",
    "\n",
    "# Function to detect square-bounded objects (e.g., cars) using YOLOv4 and display bounding boxes with distances\n",
    "def detect_square_bounded_objects(frame, net, classes, lidar_data):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_names = net.getUnconnectedOutLayersNames()\n",
    "    detections = net.forward(layer_names)\n",
    "\n",
    "    objects = []\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Adjust confidence threshold as needed\n",
    "                center_x = int(obj[0] * frame.shape[1])\n",
    "                center_y = int(obj[1] * frame.shape[0])\n",
    "                width = int(obj[2] * frame.shape[1])\n",
    "                height = int(obj[3] * frame.shape[0])\n",
    "                x, y = center_x - width // 2, center_y - height // 2\n",
    "                \n",
    "                # Check if the object is square-bounded (e.g., aspect ratio close to 1)\n",
    "                aspect_ratio = width / float(height)\n",
    "                if 0.4 <= aspect_ratio <= 1.1:  # Adjust threshold as needed\n",
    "                    objects.append((x, y, width, height, classes[class_id]))\n",
    "\n",
    "                    # Calculate the distance from LiDAR data\n",
    "                    distance = calculate_distance_from_lidar(lidar_data, (x + width // 2, y + height // 2))\n",
    "                    distance_text = f\"{distance:.2f} m\"\n",
    "\n",
    "                    # Draw a bounding box around the object\n",
    "                    cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)  # Green color\n",
    "\n",
    "                    # Display the distance\n",
    "                    cv2.putText(frame, distance_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    return objects, frame\n",
    "\n",
    "# Simulate LiDAR data\n",
    "def simulate_lidar():\n",
    "    # Simulate LiDAR data with random distance values (replace with actual LiDAR data)\n",
    "    return random.uniform(0, 200)  # Simulated distance in meters\n",
    "\n",
    "# Calculate the distance from LiDAR data\n",
    "def calculate_distance_from_lidar(lidar_data, object_center):\n",
    "    # Process LiDAR data to calculate distances to detected objects\n",
    "    # In this simplified example, we assume that LiDAR data provides distances to the center of the objects.\n",
    "    return lidar_data\n",
    "\n",
    "# Check for collision between two cars\n",
    "def check_collision(car1, car2):\n",
    "    MIN_SAFE_DISTANCE = 100  # Minimum safe distance in meters\n",
    "    \n",
    "    # Calculate the distance between the centers of car1 and car2\n",
    "    distance = np.sqrt((car1[0] - car2[0])**2 + (car1[1] - car2[1])**2)\n",
    "\n",
    "    if distance < MIN_SAFE_DISTANCE:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    # Replace these paths with your YOLOv4 model files\n",
    "    model_path = \"yolov4.weights\"\n",
    "    config_path = \"yolov4.cfg\"\n",
    "    classes_path = \"coco.names\"\n",
    "\n",
    "    # Load YOLOv4 model and classes\n",
    "    net, classes = load_yolo_model(model_path, config_path, classes_path)\n",
    "\n",
    "    # Initialize the camera (use the appropriate camera source or video file)\n",
    "    cap = cv2.VideoCapture(r\"C:\\Users\\kishore\\Downloads\\Rear_video4.mp4\")  # Replace with your video file path\n",
    "\n",
    "    # Initialize variables for collision detection\n",
    "    prev_objects = []\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # Break the loop if the video ends\n",
    "\n",
    "        # Simulate LiDAR data\n",
    "        lidar_data = simulate_lidar()\n",
    "\n",
    "        # Detect square-bounded objects (e.g., cars) using YOLOv4 and get the frame with bounding boxes and distances\n",
    "        detected_objects, frame_with_boxes = detect_square_bounded_objects(frame, net, classes, lidar_data)\n",
    "\n",
    "        \n",
    "         # Simulate LiDAR data\n",
    "        lidar_data = simulate_lidar()\n",
    "\n",
    "        # Update vehicle and object velocities dynamically (for demonstration)\n",
    "        vehicle_velocity = random.uniform(5, 20)  # Random vehicle velocity between 5 and 20 m/s\n",
    "        object_velocity = random.uniform(0, 10)   # Random object velocity between 0 and 10 m/s\n",
    "        # Check for collision between cars\n",
    "        collision = False\n",
    "        for car in detected_objects:\n",
    "            if car[4] == \"car\":  # Assuming cars are detected\n",
    "                for prev_car in prev_objects:\n",
    "                    if check_collision((car[0] + car[2] // 2, car[1] + car[3] // 2),\n",
    "                                      (prev_car[0] + prev_car[2] // 2, prev_car[1] + prev_car[3] // 2)):\n",
    "                        collision = True\n",
    "                        break\n",
    "                if collision:\n",
    "                    break\n",
    "\n",
    "        # Display collision status on the frame\n",
    "        status = \"Collision Detected!\" if collision else \"Your car is safe.\"\n",
    "        cv2.putText(frame_with_boxes, status, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        # Display the frame with bounding boxes and distances\n",
    "        cv2.imshow(\"Collision Detection\", frame_with_boxes)\n",
    "\n",
    "       # Update the previous objects list\n",
    "        prev_objects = detected_objects\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources and close the OpenCV window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6a8708",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kishore\\Desktop\\MLIA,DVP\\Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\kishore\\Desktop\\MLIA,DVP\\Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m lidar_data \u001b[39m=\u001b[39m simulate_lidar()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Detect square-bounded objects (e.g., cars) using YOLOv4 and get the frame with bounding boxes and distances\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m detected_objects, frame_with_boxes \u001b[39m=\u001b[39m detect_square_bounded_objects(frame, net, classes, lidar_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Update vehicle and object velocities dynamically (for demonstration)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m vehicle_velocity \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39muniform(\u001b[39m5\u001b[39m, \u001b[39m20\u001b[39m)  \u001b[39m# Random vehicle velocity between 5 and 20 m/s\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\kishore\\Desktop\\MLIA,DVP\\Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_square_bounded_objects\u001b[39m(frame, net, classes, lidar_data):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# ... (rest of the code remains unchanged)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kishore/Desktop/MLIA%2CDVP/Untitled.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m objects, frame\n",
      "\u001b[1;31mNameError\u001b[0m: name 'objects' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load YOLOv4 model\n",
    "def load_yolo_model(model_path, config_path, classes_path):\n",
    "    net = cv2.dnn.readNet(model_path, config_path)\n",
    "    with open(classes_path, \"r\") as f:\n",
    "        classes = f.read().strip().split(\"\\n\")\n",
    "    return net, classes\n",
    "\n",
    "# Function to detect square-bounded objects (e.g., cars) using YOLOv4 and display bounding boxes with distances\n",
    "def detect_square_bounded_objects(frame, net, classes, lidar_data):\n",
    "    # ... (rest of the code remains unchanged)\n",
    "    return objects, frame\n",
    "\n",
    "# ... (rest of the code remains unchanged)\n",
    "\n",
    "def main():\n",
    "    # Replace these paths with your YOLOv4 model files\n",
    "    model_path = \"yolov4.weights\"\n",
    "    config_path = \"yolov4.cfg\"\n",
    "    classes_path = \"coco.names\"\n",
    "\n",
    "    # Load YOLOv4 model and classes\n",
    "    net, classes = load_yolo_model(model_path, config_path, classes_path)\n",
    "\n",
    "    # Initialize the camera (use the appropriate camera source or video file)\n",
    "    cap = cv2.VideoCapture(r\"C:\\Users\\kishore\\Downloads\\Rear_video4.mp4\")  # Replace with your video file path\n",
    "\n",
    "    # Initialize variables for collision detection\n",
    "    prev_objects = []\n",
    "    \n",
    "    # Lists for storing time and distance data\n",
    "    time_data = []\n",
    "    distance_data = []\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # Break the loop if the video ends\n",
    "\n",
    "        # Simulate LiDAR data\n",
    "        lidar_data = simulate_lidar()\n",
    "\n",
    "        # Detect square-bounded objects (e.g., cars) using YOLOv4 and get the frame with bounding boxes and distances\n",
    "        detected_objects, frame_with_boxes = detect_square_bounded_objects(frame, net, classes, lidar_data)\n",
    "\n",
    "        # Update vehicle and object velocities dynamically (for demonstration)\n",
    "        vehicle_velocity = random.uniform(5, 20)  # Random vehicle velocity between 5 and 20 m/s\n",
    "        object_velocity = random.uniform(0, 10)   # Random object velocity between 0 and 10 m/s\n",
    "\n",
    "        # Check for collision between cars\n",
    "        collision = False\n",
    "        for car in detected_objects:\n",
    "            if car[4] == \"car\":  # Assuming cars are detected\n",
    "                for prev_car in prev_objects:\n",
    "                    if check_collision((car[0] + car[2] // 2, car[1] + car[3] // 2),\n",
    "                                      (prev_car[0] + prev_car[2] // 2, prev_car[1] + prev_car[3] // 2)):\n",
    "                        collision = True\n",
    "                        break\n",
    "                if collision:\n",
    "                    break\n",
    "\n",
    "        # Display collision status on the frame\n",
    "        status = \"Collision Detected!\" if collision else \"Your car is safe.\"\n",
    "        cv2.putText(frame_with_boxes, status, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Convert the frame to RGB for Matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display the frame with bounding boxes and distances\n",
    "        plt.imshow(frame_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # Update the previous objects list\n",
    "        prev_objects = detected_objects\n",
    "\n",
    "        # Store time and distance data for plotting\n",
    "        time_data.append(time_data[-1] + 1 if time_data else 0)  # Increment time\n",
    "        distance_data.append(lidar_data)  # Use simulated LiDAR data\n",
    "\n",
    "        # Plot the distance over time\n",
    "        plt.plot(time_data, distance_data, marker='o')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Distance (m)')\n",
    "        plt.title('Distance Over Time')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources and close the OpenCV window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\data.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train9\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011628 parameters, 3011612 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train9', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\labels.cache... 1201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1201/1201 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0069_jpg.rf.b38246a870ec80ebe53b1a301078e260.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0102_jpg.rf.aa233ecd406ca2eed18352746cf775a2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0112_jpg.rf.72297c3b9aaa3e2b508dc50d136460db.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0139_jpg.rf.ef9431261f07787403c47c9d09bf8e6d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0145_jpg.rf.5f1e4cdc66c8fe4289014933e7c892cf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0156_jpg.rf.60bdc27de3c473d53557d0da4d2cb264.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0216_jpg.rf.fb89c562e4b897a8ccc9fe2d3bea3868.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0320_jpg.rf.04f3384b12595f542c96d5ca9b61d66b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0332_jpg.rf.892c252773e1ba61ceb5e774beab9b88.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0339_jpg.rf.123e55500a2b08f5c52f9267e4039301.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0354_jpg.rf.0aeb8a7609d94abc9014d9e9c93911d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0392_jpg.rf.8eef0d8a2ce6e8e85302060970126dd9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0401_jpg.rf.0c5564528e360be94691d5927b092421.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0421_jpg.rf.8160531e309c34868de5c7545280ee4a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0434_jpg.rf.a2805e6367f4786a7ad173a095d74f82.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0459_jpg.rf.e588ca6eb6fc57f64b0df1714b384f2d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0462_jpg.rf.ebacbedded59c24b9b93e5e26866550d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0478_jpg.rf.de9cb525366deff4c33307ceb40bc4b8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0483_jpg.rf.f6019580b1dfaa235d4135cfd84587a8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0489_jpg.rf.e80e35ac5e13b474326676bf2f4c48dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0515_jpg.rf.8d1084494be14ce37e6b8da47919353f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0539_jpg.rf.6c7041585df6178467eaaf7f9a0b218c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0549_jpg.rf.349c104f9360197a4f49158284471fe4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0680_jpg.rf.161762ad2a80af7ac23697c2de048c3b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0684_jpg.rf.642a7e47ebad289c561e3da299fc38a5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0746_jpg.rf.83b87e78b374fe87f5871bdf50abc3d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0832_jpg.rf.09eba890a8391fd71d00cb3534d8304c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0864_jpg.rf.218fb773e6c3fe55015ae8d1b1d1ab18.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0870_jpg.rf.96d76e80ef206a9b7ab07523ffd00130.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0889_jpg.rf.2b888a447c9444c8f7598e2b8b10bf0b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0932_jpg.rf.25ab54bf1c99cf84dd0cd36003cf33f9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0949_jpg.rf.9e2556964600a9c153a956b209e2babd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0953_jpg.rf.12716ad62c09cbbf1e20a4e127271d9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0955_jpg.rf.68598858c413d3ff32a90ecb24dca112.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0989_jpg.rf.499284f76f66ea217c14cf5c2c5dbc79.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1068_jpg.rf.d6d92bd9be946fb80b99165b59f4c855.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1127_jpg.rf.0a2f47ab1d86cfa97f4bd7c04657b636.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1187_jpg.rf.8a84580b247787a6c4476fdb25ef7168.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1188_jpg.rf.2f5579e1a8cbc6982b665916cce8316e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1199_jpg.rf.78353a17338bdfefa4cef388d7a386ee.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1258_jpg.rf.1d382dfe6b4b0a1b930076764f49ab49.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1282_jpg.rf.2c215fe801275ee0c76cf453d8a7952e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1288_jpg.rf.9da7dd7f660590f243a315ee8dba9cf7.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1300_jpg.rf.83684b126e799babeb4d249c2cf03792.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1327_jpg.rf.7f8801e2b864273447b733e5c212d519.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1397_jpg.rf.22c28f3b7f1974b6e48619fcdb4c4e43.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1414_jpg.rf.e0b20fb2c716654ca83859e77fcad3cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1464_jpg.rf.cb6f1d5a86f294f3d591453b8909793b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\labels.cache... 179 images, 0 backgrounds, 0 corrupt: 100%|██████████| 179/179 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0056_jpg.rf.3c8d3908be393dae451ec7824630bc9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0097_jpg.rf.c840d34174850cf4a8618712b5612562.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0211_jpg.rf.aa9d00d6294657373245dea926197ea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0307_jpg.rf.b51f68ba5ba2887c6469eb575c1da12b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0393_jpg.rf.36dc2975f73edb800e0ea804e25a1ef0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0397_jpg.rf.76f4ad7b469c9629795bca2916f2a8e1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0645_jpg.rf.713305bfffdb4c3e19241b9ae8a3068e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0685_jpg.rf.c9a63fd403fc1bcdd21c9451d87604dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0747_jpg.rf.a7c8b7d6fb7229f6e2d2ae5325b45003.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0776_jpg.rf.a771d237d42d07f3d787b3e175bbf4d5.jpg: 1 duplicate labels removed\n",
      "Plotting labels to runs\\detect\\train9\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train9\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G       1.66      2.289      1.125          7        640: 100%|██████████| 76/76 [08:00<00:00,  6.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:23<00:00,  3.86s/it]\n",
      "                   all        179       1915      0.985     0.0908      0.339      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G      1.523      1.403      1.102          9        640: 100%|██████████| 76/76 [08:19<00:00,  6.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:59<00:00,  9.92s/it]\n",
      "                   all        179       1915      0.718      0.332      0.371      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G      1.494      1.299      1.088         51        640: 100%|██████████| 76/76 [09:19<00:00,  7.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:24<00:00,  4.00s/it]\n",
      "                   all        179       1915      0.727      0.365      0.396      0.213\n",
      "\n",
      "3 epochs completed in 0.460 hours.\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train9\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:19<00:00,  3.30s/it]\n",
      "                   all        179       1915      0.728      0.365      0.396      0.213\n",
      "               bicycle        179          6          1          0          0          0\n",
      "            pedestrian        179        223      0.668      0.278      0.367      0.178\n",
      "               scooter        179        473      0.521      0.538      0.506      0.226\n",
      "               vehicle        179       1213      0.722      0.644       0.71      0.448\n",
      "Speed: 1.5ms preprocess, 85.9ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train9\u001b[0m\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\labels.cache... 179 images, 0 backgrounds, 0 corrupt: 100%|██████████| 179/179 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0056_jpg.rf.3c8d3908be393dae451ec7824630bc9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0097_jpg.rf.c840d34174850cf4a8618712b5612562.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0211_jpg.rf.aa9d00d6294657373245dea926197ea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0307_jpg.rf.b51f68ba5ba2887c6469eb575c1da12b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0393_jpg.rf.36dc2975f73edb800e0ea804e25a1ef0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0397_jpg.rf.76f4ad7b469c9629795bca2916f2a8e1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0645_jpg.rf.713305bfffdb4c3e19241b9ae8a3068e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0685_jpg.rf.c9a63fd403fc1bcdd21c9451d87604dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0747_jpg.rf.a7c8b7d6fb7229f6e2d2ae5325b45003.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0776_jpg.rf.a771d237d42d07f3d787b3e175bbf4d5.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:20<00:00,  1.67s/it]\n",
      "                   all        179       1915      0.728      0.365      0.396      0.213\n",
      "               bicycle        179          6          1          0          0          0\n",
      "            pedestrian        179        223      0.668      0.278      0.367      0.178\n",
      "               scooter        179        473      0.521      0.538      0.506      0.226\n",
      "               vehicle        179       1213      0.722      0.644       0.71      0.448\n",
      "Speed: 1.5ms preprocess, 86.6ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "model.train(data=r\"C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\data.yaml\", epochs=3)\n",
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011628 parameters, 3011612 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\labels.cache... 1201 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1201/1201 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0069_jpg.rf.b38246a870ec80ebe53b1a301078e260.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0102_jpg.rf.aa233ecd406ca2eed18352746cf775a2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0112_jpg.rf.72297c3b9aaa3e2b508dc50d136460db.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0139_jpg.rf.ef9431261f07787403c47c9d09bf8e6d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0145_jpg.rf.5f1e4cdc66c8fe4289014933e7c892cf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0156_jpg.rf.60bdc27de3c473d53557d0da4d2cb264.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0216_jpg.rf.fb89c562e4b897a8ccc9fe2d3bea3868.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0320_jpg.rf.04f3384b12595f542c96d5ca9b61d66b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0332_jpg.rf.892c252773e1ba61ceb5e774beab9b88.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0339_jpg.rf.123e55500a2b08f5c52f9267e4039301.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0354_jpg.rf.0aeb8a7609d94abc9014d9e9c93911d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0392_jpg.rf.8eef0d8a2ce6e8e85302060970126dd9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0401_jpg.rf.0c5564528e360be94691d5927b092421.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0421_jpg.rf.8160531e309c34868de5c7545280ee4a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0434_jpg.rf.a2805e6367f4786a7ad173a095d74f82.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0459_jpg.rf.e588ca6eb6fc57f64b0df1714b384f2d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0462_jpg.rf.ebacbedded59c24b9b93e5e26866550d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0478_jpg.rf.de9cb525366deff4c33307ceb40bc4b8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0483_jpg.rf.f6019580b1dfaa235d4135cfd84587a8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0489_jpg.rf.e80e35ac5e13b474326676bf2f4c48dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0515_jpg.rf.8d1084494be14ce37e6b8da47919353f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0539_jpg.rf.6c7041585df6178467eaaf7f9a0b218c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0549_jpg.rf.349c104f9360197a4f49158284471fe4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0680_jpg.rf.161762ad2a80af7ac23697c2de048c3b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0684_jpg.rf.642a7e47ebad289c561e3da299fc38a5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0746_jpg.rf.83b87e78b374fe87f5871bdf50abc3d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0832_jpg.rf.09eba890a8391fd71d00cb3534d8304c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0864_jpg.rf.218fb773e6c3fe55015ae8d1b1d1ab18.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0870_jpg.rf.96d76e80ef206a9b7ab07523ffd00130.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0889_jpg.rf.2b888a447c9444c8f7598e2b8b10bf0b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0932_jpg.rf.25ab54bf1c99cf84dd0cd36003cf33f9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0949_jpg.rf.9e2556964600a9c153a956b209e2babd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0953_jpg.rf.12716ad62c09cbbf1e20a4e127271d9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0955_jpg.rf.68598858c413d3ff32a90ecb24dca112.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\0989_jpg.rf.499284f76f66ea217c14cf5c2c5dbc79.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1068_jpg.rf.d6d92bd9be946fb80b99165b59f4c855.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1127_jpg.rf.0a2f47ab1d86cfa97f4bd7c04657b636.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1187_jpg.rf.8a84580b247787a6c4476fdb25ef7168.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1188_jpg.rf.2f5579e1a8cbc6982b665916cce8316e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1199_jpg.rf.78353a17338bdfefa4cef388d7a386ee.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1258_jpg.rf.1d382dfe6b4b0a1b930076764f49ab49.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1282_jpg.rf.2c215fe801275ee0c76cf453d8a7952e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1288_jpg.rf.9da7dd7f660590f243a315ee8dba9cf7.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1300_jpg.rf.83684b126e799babeb4d249c2cf03792.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1327_jpg.rf.7f8801e2b864273447b733e5c212d519.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1397_jpg.rf.22c28f3b7f1974b6e48619fcdb4c4e43.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1414_jpg.rf.e0b20fb2c716654ca83859e77fcad3cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\train\\images\\1464_jpg.rf.cb6f1d5a86f294f3d591453b8909793b.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\labels.cache... 179 images, 0 backgrounds, 0 corrupt: 100%|██████████| 179/179 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0056_jpg.rf.3c8d3908be393dae451ec7824630bc9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0097_jpg.rf.c840d34174850cf4a8618712b5612562.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0211_jpg.rf.aa9d00d6294657373245dea926197ea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0307_jpg.rf.b51f68ba5ba2887c6469eb575c1da12b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0393_jpg.rf.36dc2975f73edb800e0ea804e25a1ef0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0397_jpg.rf.76f4ad7b469c9629795bca2916f2a8e1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0645_jpg.rf.713305bfffdb4c3e19241b9ae8a3068e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0685_jpg.rf.c9a63fd403fc1bcdd21c9451d87604dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0747_jpg.rf.a7c8b7d6fb7229f6e2d2ae5325b45003.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0776_jpg.rf.a771d237d42d07f3d787b3e175bbf4d5.jpg: 1 duplicate labels removed\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20         0G       1.66      2.289      1.125          7        640: 100%|██████████| 76/76 [09:40<00:00,  7.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.63s/it]\n",
      "                   all        179       1915      0.985     0.0908      0.339      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20         0G      1.564      1.438      1.118          9        640: 100%|██████████| 76/76 [09:59<00:00,  7.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:29<00:00,  4.92s/it]\n",
      "                   all        179       1915      0.732      0.309      0.352      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20         0G      1.559      1.363      1.118         51        640: 100%|██████████| 76/76 [09:33<00:00,  7.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:28<00:00,  4.80s/it]\n",
      "                   all        179       1915      0.692      0.354      0.378      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20         0G       1.56      1.305       1.11         27        640: 100%|██████████| 76/76 [09:43<00:00,  7.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:28<00:00,  4.71s/it]\n",
      "                   all        179       1915        0.7      0.381      0.399      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20         0G      1.509      1.226      1.095          6        640: 100%|██████████| 76/76 [09:09<00:00,  7.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.59s/it]\n",
      "                   all        179       1915      0.755      0.333      0.388        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20         0G      1.476      1.152      1.081         18        640: 100%|██████████| 76/76 [09:08<00:00,  7.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:30<00:00,  5.09s/it]\n",
      "                   all        179       1915      0.727      0.367      0.409      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20         0G      1.467       1.12      1.074          9        640: 100%|██████████| 76/76 [09:17<00:00,  7.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.50s/it]\n",
      "                   all        179       1915      0.744      0.358      0.413      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20         0G      1.447      1.093      1.073         38        640: 100%|██████████| 76/76 [09:10<00:00,  7.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.59s/it]\n",
      "                   all        179       1915      0.763      0.387      0.433      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20         0G      1.423      1.061       1.06          5        640: 100%|██████████| 76/76 [09:06<00:00,  7.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:26<00:00,  4.47s/it]\n",
      "                   all        179       1915      0.757      0.393      0.441      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20         0G      1.402      1.015      1.054         23        640: 100%|██████████| 76/76 [09:23<00:00,  7.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.54s/it]\n",
      "                   all        179       1915      0.726      0.386      0.435      0.238\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20         0G      1.358      1.014      1.036         14        640: 100%|██████████| 76/76 [09:12<00:00,  7.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:27<00:00,  4.59s/it]\n",
      "                   all        179       1915      0.741      0.393      0.442      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20         0G      1.341      0.964      1.039          7        640: 100%|██████████| 76/76 [12:33<00:00,  9.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:23<00:00,  3.89s/it]\n",
      "                   all        179       1915      0.801      0.382      0.453      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20         0G      1.335     0.9667      1.033         17        640: 100%|██████████| 76/76 [07:58<00:00,  6.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:26<00:00,  4.41s/it]\n",
      "                   all        179       1915      0.772      0.386      0.455      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20         0G      1.307     0.9211      1.022          8        640: 100%|██████████| 76/76 [08:18<00:00,  6.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:25<00:00,  4.17s/it]\n",
      "                   all        179       1915      0.744      0.395      0.453      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20         0G      1.298     0.9074      1.019         10        640: 100%|██████████| 76/76 [07:54<00:00,  6.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:22<00:00,  3.73s/it]\n",
      "                   all        179       1915      0.769      0.411       0.47      0.261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20         0G      1.274     0.8905      1.009         17        640: 100%|██████████| 76/76 [07:53<00:00,  6.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:22<00:00,  3.76s/it]\n",
      "                   all        179       1915      0.752      0.415       0.47       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20         0G      1.264     0.8668      1.009          7        640: 100%|██████████| 76/76 [07:52<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:22<00:00,  3.74s/it]\n",
      "                   all        179       1915      0.799      0.403      0.475      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20         0G      1.232      0.841      1.001          5        640: 100%|██████████| 76/76 [07:58<00:00,  6.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:22<00:00,  3.74s/it]\n",
      "                   all        179       1915      0.782      0.417      0.476      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20         0G      1.218     0.8189      0.994          8        640: 100%|██████████| 76/76 [07:41<00:00,  6.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:21<00:00,  3.57s/it]\n",
      "                   all        179       1915      0.801      0.399      0.481       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20         0G      1.206     0.8014     0.9872          7        640: 100%|██████████| 76/76 [07:25<00:00,  5.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:21<00:00,  3.57s/it]\n",
      "                   all        179       1915      0.785      0.414       0.48      0.268\n",
      "\n",
      "20 epochs completed in 3.140 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:17<00:00,  2.94s/it]\n",
      "                   all        179       1915        0.8      0.399      0.482      0.269\n",
      "               bicycle        179          6          1          0    0.00686    0.00481\n",
      "            pedestrian        179        223      0.747      0.336      0.465      0.235\n",
      "               scooter        179        473      0.654      0.569      0.669      0.317\n",
      "               vehicle        179       1213      0.801      0.692      0.785      0.521\n",
      "Speed: 1.5ms preprocess, 79.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Ultralytics YOLOv8.0.184  Python-3.11.2 torch-2.0.1+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\labels.cache... 179 images, 0 backgrounds, 0 corrupt: 100%|██████████| 179/179 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0056_jpg.rf.3c8d3908be393dae451ec7824630bc9c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0097_jpg.rf.c840d34174850cf4a8618712b5612562.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0211_jpg.rf.aa9d00d6294657373245dea926197ea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0307_jpg.rf.b51f68ba5ba2887c6469eb575c1da12b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0393_jpg.rf.36dc2975f73edb800e0ea804e25a1ef0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0397_jpg.rf.76f4ad7b469c9629795bca2916f2a8e1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0645_jpg.rf.713305bfffdb4c3e19241b9ae8a3068e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0685_jpg.rf.c9a63fd403fc1bcdd21c9451d87604dd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0747_jpg.rf.a7c8b7d6fb7229f6e2d2ae5325b45003.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\valid\\images\\0776_jpg.rf.a771d237d42d07f3d787b3e175bbf4d5.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:25<00:00,  2.15s/it]\n",
      "                   all        179       1915        0.8      0.399      0.482      0.269\n",
      "               bicycle        179          6          1          0    0.00686    0.00481\n",
      "            pedestrian        179        223      0.747      0.336      0.465      0.235\n",
      "               scooter        179        473      0.654      0.569      0.669      0.317\n",
      "               vehicle        179       1213      0.801      0.692      0.785      0.521\n",
      "Speed: 1.9ms preprocess, 114.0ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "model.train(data=r\"C:\\Users\\kishore\\Downloads\\OD.v7i.yolov8 (1)\\data.yaml\", epochs=20)\n",
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
